{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "E5vJOngiYdi7",
   "metadata": {
    "id": "E5vJOngiYdi7"
   },
   "source": [
    "# **Building a Conversational Chatbot with Langchain**\n",
    "\n",
    "# **Description:**\n",
    "In this activity, let's walk through the process of using LangChain, an open-source framework that enables the development of applications with large language models (LLMs) like OpenAIâ€™s GPT-3.5-turbo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Mq9A_sITsLiw",
   "metadata": {
    "id": "Mq9A_sITsLiw"
   },
   "source": [
    "# **Steps to Perform:**\n",
    "\n",
    "1. Set up the Environment\n",
    "2. Define a Document Loader\n",
    "3. Create a Document Splitter\n",
    "4. Embed the Text and Save it in Vector Stores\n",
    "5. Create a Retrieval Function\n",
    "6. Run the Chatbot and Understand the Code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Yz1jxPDoYeyz",
   "metadata": {
    "id": "Yz1jxPDoYeyz"
   },
   "source": [
    "# **Step 1: Set up the Environment**\n",
    "\n",
    "\n",
    "*   Import the necessary libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04a56690-a4ea-40f7-a7bf-1b84d112d41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "__import__('pysqlite3')\n",
    "import sys\n",
    "\n",
    "sys.modules['sqlite3'] = sys.modules['pysqlite3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2357726b",
   "metadata": {
    "id": "2357726b"
   },
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "import os\n",
    "import openai\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561a1db2",
   "metadata": {
    "id": "561a1db2"
   },
   "source": [
    "# **Step 2: Define a Document Loader**\n",
    "\n",
    "\n",
    "\n",
    "*  Use a document loader like PyPDF to load information from a PDF file.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "431b5328",
   "metadata": {
    "id": "431b5328"
   },
   "outputs": [],
   "source": [
    "#Using PyPDF\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "Doc_loader = PyPDFLoader(\"bcg-2022-annual-sustainability-report-apr-2023.pdf\")\n",
    "extracted_text = Doc_loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381e6367",
   "metadata": {
    "id": "381e6367"
   },
   "source": [
    "# **Step 3: Create a Document Splitter**\n",
    "\n",
    "\n",
    "*   Break down big pieces of text into smaller parts using text splitters.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "997c60d0",
   "metadata": {
    "id": "997c60d0"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter  = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"]\n",
    ")\n",
    "splitted_text=text_splitter.split_documents(extracted_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074db8d4",
   "metadata": {
    "id": "074db8d4"
   },
   "source": [
    "# **Step 4: Embed the Text and Save it in Vector Stores**\n",
    "\n",
    "\n",
    "*  Arrange a place to store and organize the text splits to make\n",
    " them searchable.\n",
    "*  Employ OpenAIEmbeddings to create a pretrained model instance, saving the results in a specified directory path.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a0bae9d",
   "metadata": {
    "id": "0a0bae9d"
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5a3ce63",
   "metadata": {
    "id": "b5a3ce63"
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be3f9f4e",
   "metadata": {
    "id": "be3f9f4e"
   },
   "outputs": [],
   "source": [
    "persist_directory = \"chroma_vector_x\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b380f97",
   "metadata": {
    "id": "5b380f97"
   },
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents=splitted_text,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d601da",
   "metadata": {
    "id": "00d601da"
   },
   "source": [
    "# **Step 5: Create a Retrieval Function**\n",
    "\n",
    "\n",
    "*   Retrieve pertinent data from storage based on user input using a retriever.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9222db36",
   "metadata": {
    "id": "9222db36"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_432/2902982056.py:2: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95613f21",
   "metadata": {
    "id": "95613f21"
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "Retriever_chain = RetrievalQA.from_chain_type(llm,\n",
    "                                       retriever=vectordb.as_retriever(),\n",
    "                                       return_source_documents=True,\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3PgxILTAZOZA",
   "metadata": {
    "id": "3PgxILTAZOZA"
   },
   "source": [
    "# **Step 6: Run the Chatbot and Understand the Code**\n",
    "\n",
    "\n",
    "*   Set up the chatbot, run it and\n",
    "interact with it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92170267",
   "metadata": {
    "id": "92170267",
    "outputId": "b4011b44-79ba-4467-eb05-9b230fe4b2ae"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter a query:  what is this document is about?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_432/3129579495.py:12: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  res=Retriever_chain(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "> Question:\n",
      "what is this document is about?\n",
      "\n",
      "> Answer (took 3.63 s.):\n",
      "This document is a report that covers various topics such as driving social impact, protecting our planet, and empowering our people. It provides information on the company's activities and initiatives in these areas. You can find more details in the sections \"Driving Social Impact,\" \"Protecting Our Planet,\" and \"Empowering Our People\" in the report.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter a query:  what is an interesting part of this document?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "> Question:\n",
      "what is an interesting part of this document?\n",
      "\n",
      "> Answer (took 2.03 s.):\n",
      "I don't have access to the specific document you are referring to. If you can provide me with some details or context from the document, I can help you identify an interesting part based on that information.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "while True:\n",
    "        query = input(\"\\nEnter a query: \")\n",
    "        if query == \"exit\":\n",
    "            break\n",
    "        if query.strip() == \"\":\n",
    "            continue\n",
    "\n",
    "        # Get the answer from the chain\n",
    "        start = time.time()\n",
    "\n",
    "        res=Retriever_chain(query)\n",
    "\n",
    "\n",
    "        # Print the result\n",
    "\n",
    "        end = time.time()\n",
    "        print(\"\\n\\n> Question:\")\n",
    "\n",
    "        print(query)\n",
    "\n",
    "        print(f\"\\n> Answer (took {round(end - start, 2)} s.):\")\n",
    "\n",
    "        print(res['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dGmMKkoZUPy",
   "metadata": {
    "id": "6dGmMKkoZUPy"
   },
   "source": [
    "# **Conclusion:**\n",
    "The code will ask the user to enter a query, get an answer from the chatbot, and print it along with how long it took to get the answer. The user can exit the chatbot by typing **exit**. If the user enters an empty query, the chatbot will ask for another query. This is the final step in creating and running the chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2689b9d5-5942-4c78-9712-1e24cce3c716",
   "metadata": {
    "id": "2689b9d5-5942-4c78-9712-1e24cce3c716"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 [3.10]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
